{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "from requests.utils import requote_uri\n",
    "import requests\n",
    "\n",
    "# Retrieve NASS API key from environment variables (you have to get your own)\n",
    "import os\n",
    "my_NASS_API_key = os.getenv('NASS_API_KEY')\n",
    "\n",
    "class c_usda_quick_stats:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Set the USDA QuickStats API key, API base URL, and output file path where CSV files will be written. \n",
    "\n",
    "        # self.api_key = 'PASTE_YOUR_API_KEY_HERE'\n",
    "        self.api_key = 'A9430A01-0F9A-38AC-9904-987B1A9D6D17'\n",
    "\n",
    "        self.base_url_api_get = 'http://quickstats.nass.usda.gov/api/api_GET/?key=' \\\n",
    "                                + self.api_key + '&'\n",
    "\n",
    "    def get_data(self, parameters, file_path, file_name):\n",
    "\n",
    "        # Call the api_GET api with the specified parameters. \n",
    "        # Write the CSV data to the specified output file.\n",
    "\n",
    "        # Create the full URL and retrieve the data from the Quick Stats server.\n",
    "        \n",
    "        full_url = self.base_url_api_get + parameters        \n",
    "        print(full_url)\n",
    "\n",
    "        try:\n",
    "            s_result = urllib.request.urlopen(full_url)\n",
    "            # print(type(s_result))\n",
    "            print(s_result.status, s_result.reason)\n",
    "            # print(s_result.status_code)\n",
    "            s_text = s_result.read().decode('utf-8')\n",
    "\n",
    "            # Create the output file and write the CSV data records to the file.\n",
    "\n",
    "            s_file_name = file_path + file_name\n",
    "            o_file = open(s_file_name, \"w\", encoding=\"utf8\")\n",
    "            o_file.write(s_text)\n",
    "            o_file.close()\n",
    "        except HTTPError as error:\n",
    "            print(error.code, error.reason)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred while fetching the data: {e}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Failed to parse the response data: {e}\")\n",
    "        except:\n",
    "            print(f\"Failed because of unknown exception; perhaps the USDA NASS site is down\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://quickstats.nass.usda.gov/api/api_GET/?key=A9430A01-0F9A-38AC-9904-987B1A9D6D17&source_desc=SURVEY&sector_desc=CROPS&commodity_desc=WHEAT&statisticcat_desc=YIELD&geographic_level=STATE&agg_level_desc=COUNTY&state_name=IDAHO&state_name=MICHIGAN&state_name=INDIANA&state_name=KENTUCKY&state_name=OHIO&state_name=ILLNOIS&state_name=WISCONSIN&state_name=MARYLAND&state_name=DELAWARE&state_name=TENNESSEE&state_name=CALIFORNIA&state_name%3DNEW%20YORK&state_name=ALABAMA&state_name%3DNEW%20JERSEY&state_name=WASHINGTON&state_name=VIRGINIA&year__GE=1990&year__LE=2022&format=CSV\n",
      "200 OK\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import urllib.parse\n",
    "\n",
    "output_dir = './'\n",
    "\n",
    "\n",
    "parameters =    'source_desc=SURVEY' +  \\\n",
    "                '&sector_desc=CROPS' + \\\n",
    "                '&commodity_desc=WHEAT' + \\\n",
    "                '&statisticcat_desc=YIELD' + \\\n",
    "                '&geographic_level=STATE' + \\\n",
    "                '&agg_level_desc=COUNTY' + \\\n",
    "                '&state_name=IDAHO' + \\\n",
    "                '&state_name=MICHIGAN' + \\\n",
    "                '&state_name=INDIANA' + \\\n",
    "                '&state_name=KENTUCKY' + \\\n",
    "                '&state_name=OHIO' + \\\n",
    "                '&state_name=ILLNOIS' + \\\n",
    "                '&state_name=WISCONSIN' + \\\n",
    "                '&state_name=MARYLAND' + \\\n",
    "                '&state_name=DELAWARE' + \\\n",
    "                '&state_name=TENNESSEE' + \\\n",
    "                '&state_name=CALIFORNIA' + \\\n",
    "                '&' + urllib.parse.quote('state_name=NEW YORK') + \\\n",
    "                '&state_name=ALABAMA' + \\\n",
    "                '&' + urllib.parse.quote('state_name=NEW JERSEY') + \\\n",
    "                '&state_name=WASHINGTON' + \\\n",
    "                '&state_name=VIRGINIA' + \\\n",
    "                '&year__GE=1990' + \\\n",
    "                '&year__LE=2022' + \\\n",
    "                '&format=CSV'\n",
    "\n",
    "stats = c_usda_quick_stats()\n",
    "\n",
    "#                 '&' + urllib.parse.quote('group_desc=WHEAT - YIELD, MEASURED IN BU / ACRE') + \\\n",
    "#                 '&state_name=MONTANA' + \\\n",
    "#                '&state_name=IDAHO' + \\\n",
    "#                '&state_name=NORTH DAKOTA' + \\\n",
    "# Including curr_timestamp() into file name to keep outputs separated during development/exploration\n",
    "stats.get_data(parameters, output_dir, f'wheat_yield_data_1990_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46432\n",
      "       year state_name county_name  Value\n",
      "22495  2003    ALABAMA     COLBERT   41.0\n",
      "22496  2000    ALABAMA     COLBERT   54.0\n",
      "22497  1999    ALABAMA     COLBERT   46.0\n",
      "22498  1998    ALABAMA     COLBERT   39.0\n",
      "22499  1996    ALABAMA     COLBERT   47.0\n",
      "...     ...        ...         ...    ...\n",
      "39434  1994  WISCONSIN    WAUKESHA   47.7\n",
      "39435  1993  WISCONSIN    WAUKESHA   33.5\n",
      "39436  1992  WISCONSIN    WAUKESHA   35.7\n",
      "39437  1991  WISCONSIN    WAUKESHA   38.7\n",
      "39438  1990  WISCONSIN    WAUKESHA   51.1\n",
      "\n",
      "[15408 rows x 4 columns]\n",
      "726\n",
      "     county_name state_name   Value\n",
      "403         LUCE   MICHIGAN    29.0\n",
      "478        MOORE  TENNESSEE    30.0\n",
      "324      JACKSON  TENNESSEE    30.0\n",
      "581  SAINT CLAIR    ALABAMA    30.0\n",
      "383        LEWIS  TENNESSEE    31.0\n",
      "..           ...        ...     ...\n",
      "1            ADA      IDAHO  3272.4\n",
      "53       BINGHAM      IDAHO  3484.6\n",
      "95        CANYON      IDAHO  3717.5\n",
      "336       JEROME      IDAHO  3798.8\n",
      "663   TWIN FALLS      IDAHO  3948.3\n",
      "\n",
      "[726 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_2 = pd.read_csv(\"wheat_yield_data_1990_2022.csv\")\n",
    "print(len(df_2))\n",
    "df_2[['short_desc']].drop_duplicates()\n",
    "\n",
    "\n",
    "df_winter = df_2[df_2['short_desc'] == \"WHEAT, WINTER - YIELD, MEASURED IN BU / ACRE\"]\n",
    "\n",
    "bad_county_names = ['OTHER COUNTIES', 'OTHER (COMBINED) COUNTIES']\n",
    "df_winter = df_winter[~df_winter.county_name.isin(bad_county_names)]\n",
    "df_winter = df_winter[df_winter['Value'] != 0]\n",
    "\n",
    "winter_wheat = df_winter[['year','state_name','county_name','Value']]\n",
    "print(winter_wheat)\n",
    "winter_wheat.to_csv(\"./winter_wheat_yield.csv\", index=False)\n",
    "\n",
    "df2 = df_winter[['state_name','county_name']].drop_duplicates()\n",
    "print(len(df2))\n",
    "\n",
    "yield_sum = df_winter.groupby(['county_name', 'state_name'])['Value'].sum().reset_index()\n",
    "\n",
    "# Sort the yield sums in descending order to get the top yielders overall\n",
    "#top_yielders = yield_sum.sort_values(ascending=True)\n",
    "\n",
    "yield_sum.sort_values('Value',ascending=True, inplace=True)\n",
    "print(yield_sum)\n",
    "yield_sum.to_csv(\"./top_yielding_counties.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import pandas as pd \n",
    "\n",
    "def geocode_county(state, county):\n",
    "    geolocator = Nominatim(user_agent=\"county_geocoder\")\n",
    "    location = geolocator.geocode(county + \", \" + state + \", USA\")\n",
    "    if location:\n",
    "        return location.longitude, location.latitude\n",
    "    else:\n",
    "        print('no lat-lon found for ', state, county)\n",
    "        return None, None\n",
    "    \n",
    "df_winter_wheat = pd.read_csv(\"winter_wheat_yield.csv\")\n",
    "\n",
    "df_winter_wheat['lon'] = df_winter_wheat.apply(lambda x: geocode_county(x['state_name'], x['county_name'])[0], axis=1)\n",
    "df_winter_wheat['lat'] = df_winter_wheat.apply(lambda x: geocode_county(x['state_name'], x['county_name'])[1], axis=1)\n",
    "\n",
    "print(df_winter_wheat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
